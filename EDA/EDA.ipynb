{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02f24ab-5538-4bee-8857-38b369e1a268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/envs/segmentation/lib/python3.7/site-packages (4.28.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62238e46-1872-430e-b836-397923343e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceff80f1-a544-45ce-bdc7-7ff2a77e897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/opt/ml/segmentation/input/data/\"\n",
    "json_all_path = \"/opt/ml/segmentation/input/data/train_all.json\"\n",
    "json_eval_path = \"/opt/ml/segmentation/input/data/val.json\"\n",
    "# json_all_data json_eval_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1360a-9f61-44fd-a7db-9ddcad7bd3c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## image size, rgb mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0109f46-6a70-440c-8777-e4443ec74b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_stats(img_dir, img_ids):\n",
    "    \"\"\"\n",
    "    데이터셋에 있는 이미지들의 크기와 RGB 평균 및 표준편차를 수집하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: 학습 데이터셋 이미지 폴더 경로 \n",
    "        img_ids: 학습 데이터셋 하위폴더 이름들\n",
    "\n",
    "    Returns:\n",
    "        img_info: 이미지들의 정보 (크기, 평균, 표준편차)\n",
    "    \"\"\"\n",
    "    img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "    for img_id in tqdm(img_ids):\n",
    "        img = np.array(Image.open(os.path.join(img_dir, img_id)))\n",
    "        h, w, _ = img.shape\n",
    "        img_info['heights'].append(h)\n",
    "        img_info['widths'].append(w)\n",
    "        img_info['means'].append(img.mean(axis=(0,1)))\n",
    "        img_info['stds'].append(img.std(axis=(0,1)))\n",
    "    return img_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43dd3ae9-37a2-46fb-a5de-a7a65bb88ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian\n",
    "with open(json_all_path, 'r') as j :\n",
    "    json_all_data = json.load(j)\n",
    "    img_all_file = []\n",
    "    \n",
    "for x in json_all_data[\"images\"]:\n",
    "    img_all_file.append(x[\"file_name\"])\n",
    "    \n",
    "# eval\n",
    "with open(json_eval_path, 'r') as j :\n",
    "    json_eval_data = json.load(j)\n",
    "    img_eval_file = []\n",
    "    \n",
    "for x in json_eval_data[\"images\"]:\n",
    "    img_eval_file.append(x[\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a40f1ae-4404-4188-8085-09b89ec69a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3272/3272 [01:45<00:00, 30.59it/s]\n",
      "100%|██████████| 655/655 [00:21<00:00, 30.77it/s]\n"
     ]
    }
   ],
   "source": [
    "img_all_info = get_img_stats(data_dir, img_all_file)\n",
    "img_eval_info = get_img_stats(data_dir, img_eval_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78e48b-4e50-4141-bb54-6832d23ddbd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d485cdc1-55a7-4939-bd0c-ad18e9b262cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images is 3272\n",
      "\n",
      "Minimum height for dataset is 512\n",
      "Maximum height for dataset is 512\n",
      "Average height for dataset is 512\n",
      "Minimum width for dataset is 512\n",
      "Maximum width for dataset is 512\n",
      "Average width for dataset is 512\n",
      "\n",
      "RGB Mean: [0.46009655 0.43957878 0.41827092]\n",
      "RGB Standard Deviation: [0.2108204  0.20766491 0.21656131]\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of images is {len(img_all_file)}')\n",
    "print()\n",
    "print(f'Minimum height for dataset is {np.min(img_all_info[\"heights\"])}')\n",
    "print(f'Maximum height for dataset is {np.max(img_all_info[\"heights\"])}')\n",
    "print(f'Average height for dataset is {int(np.mean(img_all_info[\"heights\"]))}')\n",
    "print(f'Minimum width for dataset is {np.min(img_all_info[\"widths\"])}')\n",
    "print(f'Maximum width for dataset is {np.max(img_all_info[\"widths\"])}')\n",
    "print(f'Average width for dataset is {int(np.mean(img_all_info[\"widths\"]))}')\n",
    "print()\n",
    "print(f'RGB Mean: {np.mean(img_all_info[\"means\"], axis=0) / 255.}')\n",
    "print(f'RGB Standard Deviation: {np.mean(img_all_info[\"stds\"], axis=0) / 255.}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf69d2e-82b6-40ed-9822-b331a9f0b97a",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "376bc206-b65d-4b28-a0c4-3d77a5546ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images is 655\n",
      "\n",
      "Minimum height for dataset is 512\n",
      "Maximum height for dataset is 512\n",
      "Average height for dataset is 512\n",
      "Minimum width for dataset is 512\n",
      "Maximum width for dataset is 512\n",
      "Average width for dataset is 512\n",
      "\n",
      "RGB Mean: [0.46034062 0.43985595 0.4168375 ]\n",
      "RGB Standard Deviation: [0.21103533 0.20915556 0.21880394]\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of images is {len(img_eval_file)}')\n",
    "print()\n",
    "print(f'Minimum height for dataset is {np.min(img_eval_info[\"heights\"])}')\n",
    "print(f'Maximum height for dataset is {np.max(img_eval_info[\"heights\"])}')\n",
    "print(f'Average height for dataset is {int(np.mean(img_eval_info[\"heights\"]))}')\n",
    "print(f'Minimum width for dataset is {np.min(img_eval_info[\"widths\"])}')\n",
    "print(f'Maximum width for dataset is {np.max(img_eval_info[\"widths\"])}')\n",
    "print(f'Average width for dataset is {int(np.mean(img_eval_info[\"widths\"]))}')\n",
    "print()\n",
    "print(f'RGB Mean: {np.mean(img_eval_info[\"means\"], axis=0) / 255.}')\n",
    "print(f'RGB Standard Deviation: {np.mean(img_eval_info[\"stds\"], axis=0) / 255.}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c311f-1dc8-47c4-97f4-e66c28e8eb84",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea841d-72e8-44d7-a5b8-02bdae929d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
