{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e3ed6c",
   "metadata": {
    "id": "8c7dbb27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/envs/detection/lib/python3.7/site-packages (4.62.3)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/envs/detection/lib/python3.7/site-packages (2.0.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (58.0.4)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (3.4.3)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (0.29.24)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.21.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/detection/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a4016a",
   "metadata": {
    "id": "0c243d84"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04683a0",
   "metadata": {
    "id": "239e1778"
   },
   "outputs": [],
   "source": [
    "GT_JSON = '/opt/ml/detection/dataset/train.json'\n",
    "PRED_CSV = 'submission_effcient_det_d3_50_train_batch_size_4.csv'\n",
    "# PRED_CSV = 'submission_effcient_det_d3_50_train.csv'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# load ground truth\n",
    "with open(GT_JSON, 'r') as outfile:\n",
    "    test_anno = (json.load(outfile))\n",
    "\n",
    "# load prediction\n",
    "pred_df = pd.read_csv(PRED_CSV)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb91530f",
   "metadata": {
    "id": "78d556fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/0000.jpg empty box\n",
      "train/0010.jpg empty box\n",
      "train/0011.jpg empty box\n",
      "train/0017.jpg empty box\n",
      "train/0024.jpg empty box\n",
      "train/0025.jpg empty box\n",
      "train/0040.jpg empty box\n",
      "train/0047.jpg empty box\n",
      "train/0084.jpg empty box\n",
      "train/0099.jpg empty box\n",
      "train/0111.jpg empty box\n",
      "train/0153.jpg empty box\n",
      "train/0191.jpg empty box\n",
      "train/0274.jpg empty box\n",
      "train/0278.jpg empty box\n",
      "train/0283.jpg empty box\n",
      "train/0301.jpg empty box\n",
      "train/0318.jpg empty box\n",
      "train/0341.jpg empty box\n",
      "train/0363.jpg empty box\n",
      "train/0406.jpg empty box\n",
      "train/0410.jpg empty box\n",
      "train/0438.jpg empty box\n",
      "train/0447.jpg empty box\n",
      "train/0466.jpg empty box\n",
      "train/0491.jpg empty box\n",
      "train/0496.jpg empty box\n",
      "train/0512.jpg empty box\n",
      "train/0551.jpg empty box\n",
      "train/0644.jpg empty box\n",
      "train/0705.jpg empty box\n",
      "train/0709.jpg empty box\n",
      "train/0713.jpg empty box\n",
      "train/0719.jpg empty box\n",
      "train/0723.jpg empty box\n",
      "train/0724.jpg empty box\n",
      "train/0752.jpg empty box\n",
      "train/0770.jpg empty box\n",
      "train/0771.jpg empty box\n",
      "train/0817.jpg empty box\n",
      "train/0853.jpg empty box\n",
      "train/0899.jpg empty box\n",
      "train/0911.jpg empty box\n",
      "train/0913.jpg empty box\n",
      "train/0939.jpg empty box\n",
      "train/0947.jpg empty box\n",
      "train/1015.jpg empty box\n",
      "train/1018.jpg empty box\n",
      "train/1041.jpg empty box\n",
      "train/1073.jpg empty box\n",
      "train/1075.jpg empty box\n",
      "train/1076.jpg empty box\n",
      "train/1078.jpg empty box\n",
      "train/1082.jpg empty box\n",
      "train/1086.jpg empty box\n",
      "train/1089.jpg empty box\n",
      "train/1103.jpg empty box\n",
      "train/1124.jpg empty box\n",
      "train/1166.jpg empty box\n",
      "train/1179.jpg empty box\n",
      "train/1205.jpg empty box\n",
      "train/1216.jpg empty box\n",
      "train/1226.jpg empty box\n",
      "train/1227.jpg empty box\n",
      "train/1229.jpg empty box\n",
      "train/1233.jpg empty box\n",
      "train/1237.jpg empty box\n",
      "train/1260.jpg empty box\n",
      "train/1274.jpg empty box\n",
      "train/1302.jpg empty box\n",
      "train/1310.jpg empty box\n",
      "train/1311.jpg empty box\n",
      "train/1362.jpg empty box\n",
      "train/1410.jpg empty box\n",
      "train/1454.jpg empty box\n",
      "train/1534.jpg empty box\n",
      "train/1550.jpg empty box\n",
      "train/1554.jpg empty box\n",
      "train/1568.jpg empty box\n",
      "train/1575.jpg empty box\n",
      "train/1608.jpg empty box\n",
      "train/1617.jpg empty box\n",
      "train/1627.jpg empty box\n",
      "train/1680.jpg empty box\n",
      "train/1682.jpg empty box\n",
      "train/1685.jpg empty box\n",
      "train/1763.jpg empty box\n",
      "train/1829.jpg empty box\n",
      "train/1895.jpg empty box\n",
      "train/1912.jpg empty box\n",
      "train/1942.jpg empty box\n",
      "train/1961.jpg empty box\n",
      "train/1994.jpg empty box\n",
      "train/2001.jpg empty box\n",
      "train/2032.jpg empty box\n",
      "train/2054.jpg empty box\n",
      "train/2065.jpg empty box\n",
      "train/2084.jpg empty box\n",
      "train/2092.jpg empty box\n",
      "train/2095.jpg empty box\n",
      "train/2107.jpg empty box\n",
      "train/2110.jpg empty box\n",
      "train/2132.jpg empty box\n",
      "train/2135.jpg empty box\n",
      "train/2160.jpg empty box\n",
      "train/2176.jpg empty box\n",
      "train/2179.jpg empty box\n",
      "train/2200.jpg empty box\n",
      "train/2216.jpg empty box\n",
      "train/2240.jpg empty box\n",
      "train/2244.jpg empty box\n",
      "train/2267.jpg empty box\n",
      "train/2269.jpg empty box\n",
      "train/2278.jpg empty box\n",
      "train/2306.jpg empty box\n",
      "train/2385.jpg empty box\n",
      "train/2396.jpg empty box\n",
      "train/2463.jpg empty box\n",
      "train/2500.jpg empty box\n",
      "train/2503.jpg empty box\n",
      "train/2533.jpg empty box\n",
      "train/2589.jpg empty box\n",
      "train/2627.jpg empty box\n",
      "train/2645.jpg empty box\n",
      "train/2702.jpg empty box\n",
      "train/2725.jpg empty box\n",
      "train/2726.jpg empty box\n",
      "train/2771.jpg empty box\n",
      "train/2791.jpg empty box\n",
      "train/2837.jpg empty box\n",
      "train/2842.jpg empty box\n",
      "train/2867.jpg empty box\n",
      "train/2894.jpg empty box\n",
      "train/2911.jpg empty box\n",
      "train/2923.jpg empty box\n",
      "train/2930.jpg empty box\n",
      "train/2957.jpg empty box\n",
      "train/2960.jpg empty box\n",
      "train/2976.jpg empty box\n",
      "train/2988.jpg empty box\n",
      "train/2989.jpg empty box\n",
      "train/2993.jpg empty box\n",
      "train/3060.jpg empty box\n",
      "train/3065.jpg empty box\n",
      "train/3077.jpg empty box\n",
      "train/3085.jpg empty box\n",
      "train/3103.jpg empty box\n",
      "train/3110.jpg empty box\n",
      "train/3124.jpg empty box\n",
      "train/3131.jpg empty box\n",
      "train/3161.jpg empty box\n",
      "train/3185.jpg empty box\n",
      "train/3200.jpg empty box\n",
      "train/3217.jpg empty box\n",
      "train/3228.jpg empty box\n",
      "train/3256.jpg empty box\n",
      "train/3260.jpg empty box\n",
      "train/3268.jpg empty box\n",
      "train/3303.jpg empty box\n",
      "train/3310.jpg empty box\n",
      "train/3320.jpg empty box\n",
      "train/3324.jpg empty box\n",
      "train/3330.jpg empty box\n",
      "train/3337.jpg empty box\n",
      "train/3359.jpg empty box\n",
      "train/3361.jpg empty box\n",
      "train/3363.jpg empty box\n",
      "train/3391.jpg empty box\n",
      "train/3413.jpg empty box\n",
      "train/3419.jpg empty box\n",
      "train/3438.jpg empty box\n",
      "train/3453.jpg empty box\n",
      "train/3466.jpg empty box\n",
      "train/3589.jpg empty box\n",
      "train/3603.jpg empty box\n",
      "train/3609.jpg empty box\n",
      "train/3649.jpg empty box\n",
      "train/3667.jpg empty box\n",
      "train/3672.jpg empty box\n",
      "train/3675.jpg empty box\n",
      "train/3733.jpg empty box\n",
      "train/3745.jpg empty box\n",
      "train/3760.jpg empty box\n",
      "train/3782.jpg empty box\n",
      "train/3788.jpg empty box\n",
      "train/3789.jpg empty box\n",
      "train/3791.jpg empty box\n",
      "train/3834.jpg empty box\n",
      "train/3874.jpg empty box\n",
      "train/3890.jpg empty box\n",
      "train/3904.jpg empty box\n",
      "train/3910.jpg empty box\n",
      "train/3914.jpg empty box\n",
      "train/3924.jpg empty box\n",
      "train/3932.jpg empty box\n",
      "train/3939.jpg empty box\n",
      "train/3949.jpg empty box\n",
      "train/3957.jpg empty box\n",
      "train/3963.jpg empty box\n",
      "train/3973.jpg empty box\n",
      "train/4008.jpg empty box\n",
      "train/4016.jpg empty box\n",
      "train/4040.jpg empty box\n",
      "train/4044.jpg empty box\n",
      "train/4063.jpg empty box\n",
      "train/4113.jpg empty box\n",
      "train/4126.jpg empty box\n",
      "train/4134.jpg empty box\n",
      "train/4147.jpg empty box\n",
      "train/4171.jpg empty box\n",
      "train/4218.jpg empty box\n",
      "train/4256.jpg empty box\n",
      "train/4297.jpg empty box\n",
      "train/4309.jpg empty box\n",
      "train/4311.jpg empty box\n",
      "train/4323.jpg empty box\n",
      "train/4329.jpg empty box\n",
      "train/4335.jpg empty box\n",
      "train/4345.jpg empty box\n",
      "train/4349.jpg empty box\n",
      "train/4353.jpg empty box\n",
      "train/4365.jpg empty box\n",
      "train/4382.jpg empty box\n",
      "train/4399.jpg empty box\n",
      "train/4421.jpg empty box\n",
      "train/4424.jpg empty box\n",
      "train/4429.jpg empty box\n",
      "train/4438.jpg empty box\n",
      "train/4459.jpg empty box\n",
      "train/4490.jpg empty box\n",
      "train/4510.jpg empty box\n",
      "train/4517.jpg empty box\n",
      "train/4543.jpg empty box\n",
      "train/4544.jpg empty box\n",
      "train/4569.jpg empty box\n",
      "train/4593.jpg empty box\n",
      "train/4612.jpg empty box\n",
      "train/4614.jpg empty box\n",
      "train/4615.jpg empty box\n",
      "train/4658.jpg empty box\n",
      "train/4661.jpg empty box\n",
      "train/4684.jpg empty box\n",
      "train/4689.jpg empty box\n",
      "train/4694.jpg empty box\n",
      "train/4701.jpg empty box\n",
      "train/4702.jpg empty box\n",
      "train/4753.jpg empty box\n",
      "train/4774.jpg empty box\n",
      "train/4779.jpg empty box\n",
      "train/4780.jpg empty box\n",
      "train/4809.jpg empty box\n",
      "train/4832.jpg empty box\n",
      "train/4839.jpg empty box\n",
      "train/4843.jpg empty box\n",
      "train/4844.jpg empty box\n",
      "train/4860.jpg empty box\n",
      "train/4873.jpg empty box\n",
      "train/4880.jpg empty box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4883it [00:00, 10082.02it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[\n",
    "    [file_name 1, confidence_score, x_min, x_max, y_min, y_max], \n",
    "    [file_name 2 confidence_score, x_min, x_max, y_min, y_max],\n",
    "    ,,,\n",
    "    [file_name , confidence_score, x_min, x_max, y_min, y_max]\n",
    "]\n",
    "'''\n",
    "    \n",
    "new_pred = []\n",
    "\n",
    "file_names = pred_df['image_id'].values.tolist()\n",
    "bboxes = pred_df['PredictionString'].values.tolist()\n",
    "    \n",
    "'''\n",
    "create new_pred\n",
    "'''\n",
    "    \n",
    "for i, bbox in enumerate(bboxes):\n",
    "    if isinstance(bbox, float):\n",
    "        print(f'{file_names[i]} empty box')\n",
    "\n",
    "for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "    boxes = np.array(str(bbox).split(' '))\n",
    "    \n",
    "    if len(boxes) % 6 == 1:\n",
    "        boxes = boxes[:-1].reshape(-1, 6)\n",
    "    elif len(boxes) % 6 == 0:\n",
    "        boxes = boxes.reshape(-1, 6)\n",
    "    else:\n",
    "        raise Exception('error', 'invalid box count')\n",
    "    for box in boxes:\n",
    "        new_pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0401d70a",
   "metadata": {
    "id": "12e02aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[\n",
    "    [file_name 1, confidence_score, x_min, x_max, y_min, y_max], \n",
    "    [file_name 2, confidence_score, x_min, x_max, y_min, y_max],\n",
    "    ,,,\n",
    "    [file_name , confidence_score, x_min, x_max, y_min, y_max]\n",
    "]\n",
    "'''\n",
    "    \n",
    "gt = []\n",
    "\n",
    "'''\n",
    "create gt\n",
    "'''\n",
    "    \n",
    "coco = COCO(GT_JSON)\n",
    "   \n",
    "'''\n",
    "coco.getImgIds(): return image id list\n",
    "    \n",
    "coco.loadImgs(image_id): return image_info\n",
    "    \n",
    "image_info['file_name']: return file name\n",
    "   \n",
    "coco.getAnnIds(imgIds=image_info['id']): return annotation id\n",
    "    \n",
    "coco.loadAnns(ann_ids): return annotation information list (annotation_info_list)\n",
    "    \n",
    "annotation_info_list[i]['bbox']: return i'th annotation [x_min, y_min, w, h]\n",
    "    \n",
    "annotation_info_list[i]['category_id']: return i'th annotation category\n",
    "    \n",
    "'''\n",
    "    \n",
    "for image_id in coco.getImgIds():\n",
    "        \n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco.loadAnns(annotation_id)\n",
    "        \n",
    "    file_name = image_info['file_name']\n",
    "        \n",
    "    for annotation in annotation_info_list:\n",
    "        gt.append([file_name, annotation['category_id'],\n",
    "                   float(annotation['bbox'][0]),\n",
    "                   float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                   float(annotation['bbox'][1]),\n",
    "                   (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57ff151",
   "metadata": {
    "id": "5f828493"
   },
   "outputs": [],
   "source": [
    "def compute_overlap(boxes, query_boxes):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        a: (N, 4) ndarray of float\n",
    "        b: (K, 4) ndarray of float\n",
    "    Returns\n",
    "        overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
    "    \"\"\"\n",
    "    N = boxes.shape[0]\n",
    "    K = query_boxes.shape[0]\n",
    "    overlaps = np.zeros((N, K), dtype=np.float64)\n",
    "    for k in range(K):\n",
    "        box_area = (\n",
    "            (query_boxes[k, 2] - query_boxes[k, 0]) *\n",
    "            (query_boxes[k, 3] - query_boxes[k, 1])\n",
    "        )\n",
    "        for n in range(N):\n",
    "            iw = (\n",
    "                min(boxes[n, 2], query_boxes[k, 2]) -\n",
    "                max(boxes[n, 0], query_boxes[k, 0])\n",
    "            )\n",
    "            if iw > 0:\n",
    "                ih = (\n",
    "                    min(boxes[n, 3], query_boxes[k, 3]) -\n",
    "                    max(boxes[n, 1], query_boxes[k, 1])\n",
    "                )\n",
    "                if ih > 0:\n",
    "                    ua = np.float64(\n",
    "                        (boxes[n, 2] - boxes[n, 0]) *\n",
    "                        (boxes[n, 3] - boxes[n, 1]) +\n",
    "                        box_area - iw * ih\n",
    "                    )\n",
    "                    overlaps[n, k] = iw * ih / ua\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "183e0ab5",
   "metadata": {
    "id": "adbb4699"
   },
   "outputs": [],
   "source": [
    "def get_real_annotations(table):\n",
    "    res = dict()\n",
    "    ids = table['ImageID'].values.astype(np.str)\n",
    "    labels = table['LabelName'].values.astype(np.str)\n",
    "    xmin = table['XMin'].values.astype(np.float32)\n",
    "    xmax = table['XMax'].values.astype(np.float32)\n",
    "    ymin = table['YMin'].values.astype(np.float32)\n",
    "    ymax = table['YMax'].values.astype(np.float32)\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        id = ids[i]\n",
    "        label = labels[i]\n",
    "        if id not in res:\n",
    "            res[id] = dict()\n",
    "        if label not in res[id]:\n",
    "            res[id][label] = []\n",
    "        box = [xmin[i], ymin[i], xmax[i], ymax[i]]\n",
    "        res[id][label].append(box)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_detections(table):\n",
    "    res = dict()\n",
    "    ids = table['ImageID'].values.astype(np.str)\n",
    "    labels = table['LabelName'].values.astype(np.str)\n",
    "    scores = table['Conf'].values.astype(np.float32)\n",
    "    xmin = table['XMin'].values.astype(np.float32)\n",
    "    xmax = table['XMax'].values.astype(np.float32)\n",
    "    ymin = table['YMin'].values.astype(np.float32)\n",
    "    ymax = table['YMax'].values.astype(np.float32)\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        id = ids[i]\n",
    "        label = labels[i]\n",
    "        if id not in res:\n",
    "            res[id] = dict()\n",
    "        if label not in res[id]:\n",
    "            res[id][label] = []\n",
    "        box = [xmin[i], ymin[i], xmax[i], ymax[i], scores[i]]\n",
    "        res[id][label].append(box)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def _compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04846046",
   "metadata": {
    "id": "b3ae4b69"
   },
   "outputs": [],
   "source": [
    "def mean_average_precision_for_boxes(ann, pred, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    :param ann: path to CSV-file with annotations or numpy array of shape (N, 6)\n",
    "    :param pred: path to CSV-file with predictions (detections) or numpy array of shape (N, 7)\n",
    "    :param iou_threshold: IoU between boxes which count as 'match'. Default: 0.5\n",
    "    :return: tuple, where first value is mAP and second values is dict with AP for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(ann, str):\n",
    "        valid = pd.read_csv(ann)\n",
    "    else:\n",
    "        valid = pd.DataFrame(ann, columns=['ImageID', 'LabelName', 'XMin', 'XMax', 'YMin', 'YMax'])\n",
    "\n",
    "    if isinstance(pred, str):\n",
    "        preds = pd.read_csv(pred)\n",
    "    else:\n",
    "        preds = pd.DataFrame(pred, columns=['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax'])\n",
    "\n",
    "    ann_unique = valid['ImageID'].unique()\n",
    "    preds_unique = preds['ImageID'].unique()\n",
    "\n",
    "    print('Number of files in annotations: {}'.format(len(ann_unique)))\n",
    "    print('Number of files in predictions: {}'.format(len(preds_unique)))\n",
    "\n",
    "\n",
    "    unique_classes = valid['LabelName'].unique().astype(np.str)\n",
    "    \n",
    "    print('Unique classes: {}'.format(len(unique_classes)))\n",
    "\n",
    "    all_detections = get_detections(preds)\n",
    "    all_annotations = get_real_annotations(valid)\n",
    "    \n",
    "    print('Detections length: {}'.format(len(all_detections)))\n",
    "    print('Annotations length: {}'.format(len(all_annotations)))\n",
    "\n",
    "    average_precisions = {}\n",
    "    for zz, label in enumerate(sorted(unique_classes)):\n",
    "\n",
    "        # Negative class\n",
    "        if str(label) == 'nan':\n",
    "            continue\n",
    "\n",
    "        false_positives = []\n",
    "        true_positives = []\n",
    "        scores = []\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(len(ann_unique)):\n",
    "            detections = []\n",
    "            annotations = []\n",
    "            id = ann_unique[i]\n",
    "            if id in all_detections:\n",
    "                if label in all_detections[id]:\n",
    "                    detections = all_detections[id][label]\n",
    "            if id in all_annotations:\n",
    "                if label in all_annotations[id]:\n",
    "                    annotations = all_annotations[id][label]\n",
    "\n",
    "            if len(detections) == 0 and len(annotations) == 0:\n",
    "                continue\n",
    "\n",
    "            num_annotations += len(annotations)\n",
    "            detected_annotations = []\n",
    "\n",
    "            annotations = np.array(annotations, dtype=np.float64)\n",
    "            for d in detections:\n",
    "                scores.append(d[4])\n",
    "\n",
    "                if len(annotations) == 0:\n",
    "                    false_positives.append(1)\n",
    "                    true_positives.append(0)\n",
    "                    continue\n",
    "\n",
    "                overlaps = compute_overlap(np.expand_dims(np.array(d, dtype=np.float64), axis=0), annotations)\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                    false_positives.append(0)\n",
    "                    true_positives.append(1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives.append(1)\n",
    "                    true_positives.append(0)\n",
    "\n",
    "        if num_annotations == 0:\n",
    "            average_precisions[label] = 0, 0\n",
    "            continue\n",
    "\n",
    "        false_positives = np.array(false_positives)\n",
    "        true_positives = np.array(true_positives)\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = _compute_ap(recall, precision)\n",
    "        average_precisions[label] = average_precision, num_annotations\n",
    "        s1 = \"{:30s} | {:.6f} | {:7d}\".format(label, average_precision, int(num_annotations))\n",
    "        print(s1)\n",
    "\n",
    "    present_classes = 0\n",
    "    precision = 0\n",
    "    for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "        if num_annotations > 0:\n",
    "            present_classes += 1\n",
    "            precision += average_precision\n",
    "            \n",
    "    mean_ap = precision / present_classes\n",
    "    print('mAP: {:.6f}'.format(mean_ap))\n",
    "    \n",
    "    return mean_ap, average_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60210495-da95-4243-9307-274ebc40a2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train/0000.jpg', 0, 197.6, 745.4, 193.7, 663.4],\n",
       " ['train/0001.jpg', 3, 0.0, 57.6, 407.4, 588.0],\n",
       " ['train/0001.jpg', 7, 0.0, 144.6, 455.6, 637.2],\n",
       " ['train/0001.jpg', 4, 722.3, 996.5999999999999, 313.4, 565.3],\n",
       " ['train/0001.jpg', 5, 353.2, 586.9, 671.0, 774.4],\n",
       " ['train/0001.jpg', 5, 3.7, 781.9000000000001, 448.5, 690.5],\n",
       " ['train/0001.jpg', 0, 425.3, 641.7, 681.9, 861.7],\n",
       " ['train/0001.jpg', 7, 92.4, 231.6, 601.7, 654.8000000000001],\n",
       " ['train/0001.jpg', 0, 622.4, 695.1999999999999, 686.5, 780.7],\n",
       " ['train/0002.jpg', 3, 267.9, 899.5, 165.2, 678.2]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b138d22-849c-402a-91f4-0e62f5d49b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train/0001.jpg',\n",
       "  '7',\n",
       "  '0.8273342',\n",
       "  0.4756622314453125,\n",
       "  155.73626708984375,\n",
       "  450.24151611328125,\n",
       "  647.1145629882812],\n",
       " ['train/0001.jpg',\n",
       "  '4',\n",
       "  '0.68532103',\n",
       "  719.5620727539062,\n",
       "  986.5067749023438,\n",
       "  295.9759521484375,\n",
       "  569.048828125],\n",
       " ['train/0001.jpg',\n",
       "  '7',\n",
       "  '0.45605806',\n",
       "  92.7458724975586,\n",
       "  235.04776000976562,\n",
       "  597.154296875,\n",
       "  659.9893798828125],\n",
       " ['train/0001.jpg',\n",
       "  '9',\n",
       "  '0.37374008',\n",
       "  27.6329345703125,\n",
       "  775.2059326171875,\n",
       "  442.7140197753906,\n",
       "  741.82861328125],\n",
       " ['train/0001.jpg',\n",
       "  '4',\n",
       "  '0.35860425',\n",
       "  40.368133544921875,\n",
       "  779.786376953125,\n",
       "  439.53350830078125,\n",
       "  741.7778930664062],\n",
       " ['train/0001.jpg',\n",
       "  '4',\n",
       "  '0.29569444',\n",
       "  357.2955322265625,\n",
       "  572.0662231445312,\n",
       "  663.8292236328125,\n",
       "  775.4056396484375],\n",
       " ['train/0001.jpg',\n",
       "  '5',\n",
       "  '0.2738941',\n",
       "  357.2955322265625,\n",
       "  572.0662231445312,\n",
       "  663.8292236328125,\n",
       "  775.4056396484375],\n",
       " ['train/0001.jpg',\n",
       "  '7',\n",
       "  '0.19315323',\n",
       "  46.160850524902344,\n",
       "  236.86734008789062,\n",
       "  450.83441162109375,\n",
       "  651.1080932617188],\n",
       " ['train/0001.jpg',\n",
       "  '9',\n",
       "  '0.19230662',\n",
       "  46.160850524902344,\n",
       "  236.86734008789062,\n",
       "  450.83441162109375,\n",
       "  651.1080932617188],\n",
       " ['train/0001.jpg',\n",
       "  '4',\n",
       "  '0.18727387',\n",
       "  690.08935546875,\n",
       "  1000.2838134765625,\n",
       "  122.03067016601562,\n",
       "  548.9632568359375]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789c3519",
   "metadata": {
    "id": "a0938f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 4883\n",
      "Number of files in predictions: 4625\n",
      "Unique classes: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections length: 4625\n",
      "Annotations length: 4883\n",
      "0                              | 0.000000 |    3966\n",
      "1                              | 0.646945 |    6352\n",
      "2                              | 0.713611 |     897\n",
      "3                              | 0.640260 |     936\n",
      "4                              | 0.534331 |     982\n",
      "5                              | 0.618766 |    2943\n",
      "6                              | 0.675804 |    1263\n",
      "7                              | 0.804650 |    5178\n",
      "8                              | 0.466301 |     159\n",
      "9                              | 0.641704 |     468\n",
      "mAP: 0.574237\n",
      "0.5742372755188985\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calculate mAP\n",
    "'''\n",
    "\n",
    "mean_ap, average_precisions = mean_average_precision_for_boxes(gt[:10], new_pred[:10], iou_threshold=0.5)\n",
    "\n",
    "print(mean_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2eff2",
   "metadata": {
    "id": "ef39d7ef"
   },
   "outputs": [],
   "source": [
    "\n",
    "# submission_mmdetection_example\n",
    "# mAP : mAP: 0.688915\n",
    "\n",
    "# submission_effcient_det_d3_50_train == submission_effcient_det_d3_50_train_batch_size_1\n",
    "# mAP: 0.574237\n",
    "\n",
    "\n",
    "# submission_effcient_det_d3_26_train_batch_size_4\n",
    "# mAP: 0.277228"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "metric_challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
